{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Language Modeling Part 2:\n",
        "\n",
        "We have trained a character level MLP (Multi Layer Perceptron) on a dataset containing ~32k names. The model predicts new names after training."
      ],
      "metadata": {
        "id": "AYGA9ZFKS60d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technical Details:\n",
        "- The architecture has three layers -\n",
        "    - First is the embedding layer which creates an embedding for the input tokens\n",
        "    - Second is the hidden layer which learns patterns in the data\n",
        "    - Third is the output layer which outputs logits (logarithmic counts)\n",
        "- Activation of the hidden layer is tanh\n",
        "- Loss being used is the classification cross entropy loss a.k.a average negative log likelihood loss\n",
        "\n",
        "Hyperparameters like numbers of neuron in hidden layer, the length of context to be used for prediction (last n characters), the size of the embedding layers, learning rate, the number of epochs, batch size, etc can be played around with"
      ],
      "metadata": {
        "id": "gTxzox4QUlY2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtJ-2Sj2Z4wy"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import random\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download\n",
        "\n",
        "names = requests.get(\"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\").text\n",
        "names = names.splitlines()"
      ],
      "metadata": {
        "id": "pSbZHuuCZ8z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lYIziujTLch",
        "outputId": "b5b9983a-98fa-4b72-f8fd-19b9f6cbc855"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# string to token conversion\n",
        "\n",
        "itos = ['.'] + sorted(list(set(\"\".join(names))))\n",
        "stoi = {ch: idx for idx, ch in enumerate(itos)}"
      ],
      "metadata": {
        "id": "k1ApfqxWerD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "\n",
        "def create_data(words, block_size=3):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for word in words:\n",
        "        window = [0] * block_size\n",
        "        word += \".\"\n",
        "        for char in word:\n",
        "            xs.append(window)\n",
        "            ys.append(stoi[char])\n",
        "\n",
        "            window = window[1:]\n",
        "            window.append(stoi[char])\n",
        "    return torch.tensor(xs), torch.tensor(ys)"
      ],
      "metadata": {
        "id": "WDqUd9q1c2Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize hyperparameters\n",
        "\n",
        "emb_dim = 10\n",
        "block_size = 4\n",
        "hidden_layer_dim = 100\n",
        "emb_size = emb_dim * block_size  # don't change this"
      ],
      "metadata": {
        "id": "PM5rqosatitD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize train, val, test datasets\n",
        "\n",
        "random.seed(17)\n",
        "random.shuffle(names)\n",
        "n1 = int(0.8 * len(names))\n",
        "n2 = int(0.9 * len(names))\n",
        "xs, ys = create_data(names, block_size)\n",
        "x_train, y_train = create_data(names[:n1], block_size)\n",
        "x_val, y_val = create_data(names[n1:n2], block_size)\n",
        "x_test, y_test = create_data(names[n2:], block_size)\n",
        "\n",
        "print(\"train -\", x_train.shape[0])\n",
        "print(\"val   -\", x_val.shape[0])\n",
        "print(\"test  -\", x_test.shape[0])\n",
        "print(\"total -\", xs.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsMkwrevgOZ9",
        "outputId": "193b2b67-22f9-4149-aca8-c9e7de3d3921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train - 182705\n",
            "val   - 22652\n",
            "test  - 22789\n",
            "total - 228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model weights\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "emb = torch.randn((27, emb_dim), requires_grad=True, generator=g)\n",
        "w1 = torch.randn((emb_size, hidden_layer_dim), requires_grad=True, generator=g)\n",
        "b1 = torch.randn(hidden_layer_dim, requires_grad=True, generator=g)\n",
        "w2 = torch.randn((hidden_layer_dim, 27), requires_grad=True, generator=g)\n",
        "b2 = torch.randn(27, requires_grad=True, generator=g)\n",
        "params = [emb, w1, b1, w2, b2]\n",
        "params_count = sum([p.nelement() for p in params])\n",
        "print(f\"{params_count=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF8uYGrBGPxh",
        "outputId": "df192ac6-7084-473d-8265-f74cb6260805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params_count=7097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "batch_size = 32\n",
        "for i in range(200001):\n",
        "\n",
        "    # creating batch\n",
        "    ix = torch.randint(0, x_train.shape[0], (batch_size,))\n",
        "\n",
        "    # forward pass\n",
        "    embs = emb[x_train[ix]]\n",
        "    preact = embs.view(-1, emb_size) @ w1 + b1\n",
        "    act = torch.tanh(preact)\n",
        "    logits = act @ w2 + b2\n",
        "    loss = F.cross_entropy(logits, y_train[ix])  # softmax (final activation) + avg neg log likelihood loss\n",
        "\n",
        "    # print loss\n",
        "    if i % 10000 == 0:\n",
        "        print(i, \"-\", round(loss.item(), 4))\n",
        "\n",
        "    # backward pass\n",
        "    for param in params:\n",
        "        param.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    lr = 0.01 if i < 100000 else 0.001\n",
        "    for param in params:\n",
        "        param.data += -lr * param.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmq4KafImlPZ",
        "outputId": "d6f1eccc-5a9d-4c21-fbd7-0c533b0ac44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - 17.584\n",
            "10000 - 2.58\n",
            "20000 - 2.7229\n",
            "30000 - 2.1249\n",
            "40000 - 2.3352\n",
            "50000 - 1.8454\n",
            "60000 - 2.3872\n",
            "70000 - 2.6873\n",
            "80000 - 2.3014\n",
            "90000 - 2.5933\n",
            "100000 - 2.3176\n",
            "110000 - 2.0669\n",
            "120000 - 2.5923\n",
            "130000 - 2.0771\n",
            "140000 - 2.5835\n",
            "150000 - 2.1807\n",
            "160000 - 2.2941\n",
            "170000 - 1.9813\n",
            "180000 - 2.3605\n",
            "190000 - 2.1533\n",
            "200000 - 2.3758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on validation data\n",
        "\n",
        "embs = emb[x_val]\n",
        "act = torch.tanh(embs.view(-1, emb_size) @ w1 + b1)\n",
        "logits = act @ w2 + b2\n",
        "loss = F.cross_entropy(logits, y_val)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1wYePGamQrr",
        "outputId": "d44b07c5-7876-4ee8-fd65-472d7d22aee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.300997018814087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "\n",
        "for _ in range(100):\n",
        "    xt = [0] * block_size\n",
        "    while True:\n",
        "        with torch.no_grad():\n",
        "            embs = emb[xt]\n",
        "            preact = embs.view(-1, emb_size) @ w1 + b1\n",
        "            act = torch.tanh(preact)\n",
        "            logits = act @ w2 + b2\n",
        "            counts = logits.exp()\n",
        "            probs = counts / counts.sum(1, keepdim=True)\n",
        "            next_idx = torch.multinomial(probs, num_samples=1, replacement=True)[0].item()\n",
        "            xt = xt[1:] + [next_idx]\n",
        "            print(itos[next_idx], end=\"\")\n",
        "            if next_idx == 0:\n",
        "                print(\"\")\n",
        "                break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo0yuoZPnCb_",
        "outputId": "ba528898-f36d-4b33-ef2c-979912de69e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alely.\n",
            "chem.\n",
            "amir.\n",
            "khaide.\n",
            "imyr.\n",
            "sa.\n",
            "ginva.\n",
            "sona.\n",
            "jano.\n",
            "ramlea.\n",
            "dile.\n",
            "jomer.\n",
            "emryah.\n",
            "gexsen.\n",
            "aban.\n",
            "leer.\n",
            "rumitha.\n",
            "laan.\n",
            "gylin.\n",
            "mary.\n",
            "jhro.\n",
            "jan.\n",
            "dareot.\n",
            "kes.\n",
            "aahanah.\n",
            "pumton.\n",
            "lusur.\n",
            "riokma.\n",
            "hamya.\n",
            "vena.\n",
            "mandah.\n",
            "isya.\n",
            "hahatan.\n",
            "paene.\n",
            "alyan.\n",
            "avdi.\n",
            "oazob.\n",
            "lontalde.\n",
            "kodze.\n",
            "jaidei.\n",
            "canru.\n",
            "balshamlie.\n",
            "azelde.\n",
            "shaislan.\n",
            "xakarnahi.\n",
            "lovenn.\n",
            "kenniel.\n",
            "waial.\n",
            "sysen.\n",
            "imiah.\n",
            "mahanis.\n",
            "ryza.\n",
            "lasie.\n",
            "asla.\n",
            "evesoa.\n",
            "kolen.\n",
            "aryan.\n",
            "dloc.\n",
            "adcisse.\n",
            "jailen.\n",
            "eylet.\n",
            "melae.\n",
            "xuej.\n",
            "malilane.\n",
            "myar.\n",
            "esnaniy.\n",
            "tiel.\n",
            "merie.\n",
            "amrit.\n",
            "emad.\n",
            "kdodettor.\n",
            "weska.\n",
            "renesharlel.\n",
            "alysa.\n",
            "brac.\n",
            "amalyn.\n",
            "adde.\n",
            "zeyva.\n",
            "dalioa.\n",
            "brusetton.\n",
            "jinieso.\n",
            "ewmespazimina.\n",
            "marel.\n",
            "mangee.\n",
            "anlad.\n",
            "alyerkerer.\n",
            "rishan.\n",
            "jaresiy.\n",
            "weri.\n",
            "anna.\n",
            "nazyn.\n",
            "nefana.\n",
            "ronva.\n",
            "noza.\n",
            "amaran.\n",
            "raah.\n",
            "aliahce.\n",
            "lonssaisrdon.\n",
            "kaikl.\n",
            "iamarvicta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test data\n",
        "\n",
        "embs = emb[x_test]\n",
        "act = torch.tanh(embs.view(-1, emb_size) @ w1 + b1)\n",
        "logits = act @ w2 + b2\n",
        "loss = F.cross_entropy(logits, y_test)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "OHI5qg2sgXCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbce7fd-ea7b-4004-8d4d-db16cf8eff43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.279118299484253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nto9R-ceu5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}